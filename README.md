# GraduateProject

搭建一个新闻推荐系统，并用web展示。

Mind 新闻推荐（Microsoft MIND / MIND-Corpus）比赛的主流解决方案可以概括为“多路召回 + 强排序 + 行为建模 + 文本语义建模”，整体是一个工业级新闻推荐范式。下面按模块给出相对成熟、在比赛中验证过的方案框架，尽量偏工程与算法实操。

首先是问题建模。MIND 本质是点击预测与排序问题，给定用户历史点击新闻序列和候选新闻集合，预测点击概率。评估指标通常是 AUC、MRR、nDCG@5/10，因此重点在排序质量而非单点分类准确率。



一、召回阶段（Candidate Generation）
召回的目标是从全量新闻中筛出几百到几千条高相关候选，保证覆盖率。

召回方式包括：
1）基于协同过滤, ItemCF：根据共现点击构建新闻相似度（常用 cosine / log 共现 / 时间衰减）

2）Bert编码新闻内容做向量召回

3）基于规则与统计，最近点击过的新闻相似内容

4）lightGCN，基于图神经网络训练得到用户和物品向量，召回用户向量*物品向量最大的物品

5）基于内容的召回，对新闻内容采用TF-IDF，做向量召回

合并结果去重后用于排序



二、特征工程（核心竞争力）
这是 MIND 成绩差异最大的部分。

1）用户行为特征

- 历史点击数（log 变换）
- 最近 1d / 3d / 7d 点击数
- 最近一次点击距当前 impression 的时间差

2）新闻侧特征

- 新闻在最近 1d / 3d / 7d 的点击数
- 最近曝光次数（如有）
- 全局点击次数（log）
- 距新闻“最近一次被点击”的时间差
- 最近 1d 是否被点击过（0/1）

3）交叉特征

- 用户向量 vs 新闻向量的相似度（cosine / dot）
- 用户最近点击新闻与候选新闻的最大 / 平均相似度
- 类别匹配度（user history category 分布 vs candidate）

4）召回来源特征

- 是否来自 itemcf（0/1）
- 是否来自 w2v
- 是否来自 bert
- 是否来自 popularity
- 召回得分（itemcf_score / bert_sim / w2v_GCN分数）

三、排序模型（Ranker）

1）Tree-based Ranker（辅助或融合）

- LightGBM / XGBoost
- 输入为精心构造的统计 + embedding 相似度特征
- 常用于模型融合或二次精排

四、训练技巧

- 负采样：impression 内负样本 + 随机负采样
- 长序列截断（保留最近行为）



